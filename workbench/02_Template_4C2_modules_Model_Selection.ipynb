{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import all the filenames\n",
    "from allfunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1  def LassoCVModel(filename):\n",
    "\n",
    "2  def OMPCVModel(filename):\n",
    "\n",
    "3  def GradientBoostingCVModel(filename):\n",
    "\n",
    "4  def RandomForestCVModel(filename):\n",
    "\n",
    "5  def RidgeCVModel(filename):\n",
    "\n",
    "6  def ElasticNetCVModel(filename):\n",
    "\n",
    "7  def SVRPolyCVModel(filename):\n",
    "\n",
    "8  def SVRSigmoidCVModel(filename):\n",
    "\n",
    "9  def SVRLinearCVModel(filename):\n",
    "\n",
    "10 def SVRRbfCVModel(filename):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wrapper():\n",
    "    if __name__ == '__main__':\n",
    "        global model_selection\n",
    "        global functionList\n",
    "        global filenames\n",
    "        \n",
    "        functionList = [ LassoCVModel, GradientBoostingCVModel, \n",
    "                 RandomForestCVModel, RidgeCVModel, ElasticNetCVModel, \n",
    "                 SVRPolyCVModel, SVRSigmoidCVModel, SVRLinearCVModel, \n",
    "                 SVRRbfCVModel ] #OMPCVModel\n",
    "\n",
    "        filenames = ['AB.pickle', 'BC.pickle', 'CD.pickle', 'AC.pickle', 'AD.pickle', 'BD.pickle' ]\n",
    "        \n",
    "        model_selection = {}\n",
    "        \n",
    "        for f in functionList:\n",
    "            print()\n",
    "            for filename in filenames:\n",
    "                out = f(filename)\n",
    "                newScore = out[filename]['train_rmse_cv_4_picking']\n",
    "\n",
    "                if filename in model_selection:\n",
    "                    #compare scores and select more accurate model\n",
    "                    oldScore = model_selection[filename]['train_rmse_cv_4_picking']\n",
    "                    if(newScore < oldScore):\n",
    "                        print(\"【【【】】】switching models for %s...\" % filename)\n",
    "                        print(\"【【【】】】newScore: %f < oldScore: %f\" % (newScore, oldScore))\n",
    "                        print(\"【【【】】】newModel: %s \\n\" % f)\n",
    "                        print(100*'_')\n",
    "                        model_selection[filename] = out[filename]\n",
    "                else:\n",
    "                    #no score to compare\n",
    "                    print(\"【【】】adding new model for %s \\n\" % filename)\n",
    "                    print(100*'_')\n",
    "                    model_selection[filename] = out[filename]\n",
    "    return model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset size read: train 127 and test 194 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 20.691380811147901}\n",
      "Lasso(alpha=20.691380811147901, copy_X=True, fit_intercept=True,\n",
      "   max_iter=10000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='random', tol=0.0001, warm_start=False)\n",
      "\n",
      "【【】】adding new model for AB.pickle \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 6.1584821106602545}\n",
      "Lasso(alpha=6.1584821106602545, copy_X=True, fit_intercept=True,\n",
      "   max_iter=10000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='random', tol=0.0001, warm_start=False)\n",
      "\n",
      "【【】】adding new model for BC.pickle \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 194 and test 127 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 1.8329807108324339}\n",
      "Lasso(alpha=1.8329807108324339, copy_X=True, fit_intercept=True,\n",
      "   max_iter=10000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='random', tol=0.0001, warm_start=False)\n",
      "\n",
      "【【】】adding new model for CD.pickle \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 129 and test 192 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 6.1584821106602545}\n",
      "Lasso(alpha=6.1584821106602545, copy_X=True, fit_intercept=True,\n",
      "   max_iter=10000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='random', tol=0.0001, warm_start=False)\n",
      "\n",
      "【【】】adding new model for AC.pickle \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 129 and test 95 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 6.1584821106602545}\n",
      "Lasso(alpha=6.1584821106602545, copy_X=True, fit_intercept=True,\n",
      "   max_iter=10000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='random', tol=0.0001, warm_start=False)\n",
      "\n",
      "【【】】adding new model for AD.pickle \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 20.691380811147901}\n",
      "Lasso(alpha=20.691380811147901, copy_X=True, fit_intercept=True,\n",
      "   max_iter=10000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='random', tol=0.0001, warm_start=False)\n",
      "\n",
      "【【】】adding new model for BD.pickle \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "Dataset size read: train 127 and test 194 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.1, 'loss': 'ls'}\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=None,\n",
      "             max_features=None, max_leaf_nodes=None,\n",
      "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=6000, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      "\n",
      "【【【】】】switching models for AB.pickle...\n",
      "【【【】】】newScore: 613.431176 < oldScore: 1159.605336\n",
      "【【【】】】newModel: <function GradientBoostingCVModel at 0x7fbddefcd7b8> \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.1, 'loss': 'ls'}\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=None,\n",
      "             max_features=None, max_leaf_nodes=None,\n",
      "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=6000, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      "\n",
      "【【【】】】switching models for BC.pickle...\n",
      "【【【】】】newScore: 509.876994 < oldScore: 886.678685\n",
      "【【【】】】newModel: <function GradientBoostingCVModel at 0x7fbddefcd7b8> \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 194 and test 127 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.01, 'loss': 'ls'}\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.01, loss='ls', max_depth=None,\n",
      "             max_features=None, max_leaf_nodes=None,\n",
      "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=6000, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      "\n",
      "【【【】】】switching models for CD.pickle...\n",
      "【【【】】】newScore: 149.578058 < oldScore: 845.398434\n",
      "【【【】】】newModel: <function GradientBoostingCVModel at 0x7fbddefcd7b8> \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 129 and test 192 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.1, 'loss': 'ls'}\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=None,\n",
      "             max_features=None, max_leaf_nodes=None,\n",
      "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=6000, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      "\n",
      "【【【】】】switching models for AC.pickle...\n",
      "【【【】】】newScore: 147.615176 < oldScore: 1045.707022\n",
      "【【【】】】newModel: <function GradientBoostingCVModel at 0x7fbddefcd7b8> \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 129 and test 95 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.001, 'loss': 'ls'}\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.001, loss='ls', max_depth=None,\n",
      "             max_features=None, max_leaf_nodes=None,\n",
      "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=6000, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      "\n",
      "【【【】】】switching models for AD.pickle...\n",
      "【【【】】】newScore: 85.983265 < oldScore: 809.608674\n",
      "【【【】】】newModel: <function GradientBoostingCVModel at 0x7fbddefcd7b8> \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.1, 'loss': 'ls'}\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=None,\n",
      "             max_features=None, max_leaf_nodes=None,\n",
      "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=6000, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n",
      "\n",
      "【【【】】】switching models for BD.pickle...\n",
      "【【【】】】newScore: 490.776589 < oldScore: 898.205223\n",
      "【【【】】】newModel: <function GradientBoostingCVModel at 0x7fbddefcd7b8> \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "Dataset size read: train 127 and test 194 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0}\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=6000, n_jobs=-1, oob_score=True, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "【【【】】】switching models for AB.pickle...\n",
      "【【【】】】newScore: 613.228035 < oldScore: 613.431176\n",
      "【【【】】】newModel: <function RandomForestCVModel at 0x7fbddefcd840> \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0}\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=6000, n_jobs=-1, oob_score=True, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "【【【】】】switching models for BC.pickle...\n",
      "【【【】】】newScore: 508.487191 < oldScore: 509.876994\n",
      "【【【】】】newModel: <function RandomForestCVModel at 0x7fbddefcd840> \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 194 and test 127 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0}\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=6000, n_jobs=-1, oob_score=True, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "【【【】】】switching models for CD.pickle...\n",
      "【【【】】】newScore: 139.115734 < oldScore: 149.578058\n",
      "【【【】】】newModel: <function RandomForestCVModel at 0x7fbddefcd840> \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 129 and test 192 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0}\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=6000, n_jobs=-1, oob_score=True, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "【【【】】】switching models for AC.pickle...\n",
      "【【【】】】newScore: 139.211516 < oldScore: 147.615176\n",
      "【【【】】】newModel: <function RandomForestCVModel at 0x7fbddefcd840> \n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Dataset size read: train 129 and test 95 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0}\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=6000, n_jobs=-1, oob_score=True, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0}\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=2,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=6000, n_jobs=-1, oob_score=True, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Dataset size read: train 127 and test 194 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 100000.0}\n",
      "Ridge(alpha=100000.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 100000.0}\n",
      "Ridge(alpha=100000.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "Dataset size read: train 194 and test 127 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 100000.0}\n",
      "Ridge(alpha=100000.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "Dataset size read: train 129 and test 192 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 100000.0}\n",
      "Ridge(alpha=100000.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "Dataset size read: train 129 and test 95 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 100000.0}\n",
      "Ridge(alpha=100000.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 100000.0}\n",
      "Ridge(alpha=100000.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "\n",
      "\n",
      "Dataset size read: train 127 and test 194 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 17.012542798525892, 'l1_ratio': 0.95}\n",
      "ElasticNet(alpha=17.012542798525892, copy_X=True, fit_intercept=True,\n",
      "      l1_ratio=0.95, max_iter=1000000.0, normalize=False, positive=False,\n",
      "      precompute=False, random_state=None, selection='cyclic', tol=1e-07,\n",
      "      warm_start=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 7.4438030132516886, 'l1_ratio': 0.9}\n",
      "ElasticNet(alpha=7.4438030132516886, copy_X=True, fit_intercept=True,\n",
      "      l1_ratio=0.9, max_iter=1000000.0, normalize=False, positive=False,\n",
      "      precompute=False, random_state=None, selection='cyclic', tol=1e-07,\n",
      "      warm_start=False)\n",
      "\n",
      "Dataset size read: train 194 and test 127 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 2.1544346900318843, 'l1_ratio': 0.9}\n",
      "ElasticNet(alpha=2.1544346900318843, copy_X=True, fit_intercept=True,\n",
      "      l1_ratio=0.9, max_iter=1000000.0, normalize=False, positive=False,\n",
      "      precompute=False, random_state=None, selection='cyclic', tol=1e-07,\n",
      "      warm_start=False)\n",
      "\n",
      "Dataset size read: train 129 and test 192 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 7.4438030132516886, 'l1_ratio': 0.9}\n",
      "ElasticNet(alpha=7.4438030132516886, copy_X=True, fit_intercept=True,\n",
      "      l1_ratio=0.9, max_iter=1000000.0, normalize=False, positive=False,\n",
      "      precompute=False, random_state=None, selection='cyclic', tol=1e-07,\n",
      "      warm_start=False)\n",
      "\n",
      "Dataset size read: train 129 and test 95 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 3.2570206556597832, 'l1_ratio': 0.9}\n",
      "ElasticNet(alpha=3.2570206556597832, copy_X=True, fit_intercept=True,\n",
      "      l1_ratio=0.9, max_iter=1000000.0, normalize=False, positive=False,\n",
      "      precompute=False, random_state=None, selection='cyclic', tol=1e-07,\n",
      "      warm_start=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 11.253355826007645, 'l1_ratio': 0.7}\n",
      "ElasticNet(alpha=11.253355826007645, copy_X=True, fit_intercept=True,\n",
      "      l1_ratio=0.7, max_iter=1000000.0, normalize=False, positive=False,\n",
      "      precompute=False, random_state=None, selection='cyclic', tol=1e-07,\n",
      "      warm_start=False)\n",
      "\n",
      "\n",
      "Dataset size read: train 127 and test 194 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-15, 'degree': 3, 'epsilon': 1.0000000000000001e-15, 'gamma': 1.0000000000000001e-15, 'kernel': 'poly'}\n",
      "SVR(C=1.0000000000000001e-15, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=1.0000000000000001e-15, gamma=1.0000000000000001e-15,\n",
      "  kernel='poly', max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-15, 'degree': 3, 'epsilon': 1.0000000000000001e-15, 'gamma': 1.0000000000000001e-15, 'kernel': 'poly'}\n",
      "SVR(C=1.0000000000000001e-15, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=1.0000000000000001e-15, gamma=1.0000000000000001e-15,\n",
      "  kernel='poly', max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 194 and test 127 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-15, 'degree': 3, 'epsilon': 1.0000000000000001e-15, 'gamma': 1.0000000000000001e-15, 'kernel': 'poly'}\n",
      "SVR(C=1.0000000000000001e-15, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=1.0000000000000001e-15, gamma=1.0000000000000001e-15,\n",
      "  kernel='poly', max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 129 and test 192 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-15, 'degree': 3, 'epsilon': 1.0000000000000001e-15, 'gamma': 1.0000000000000001e-15, 'kernel': 'poly'}\n",
      "SVR(C=1.0000000000000001e-15, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=1.0000000000000001e-15, gamma=1.0000000000000001e-15,\n",
      "  kernel='poly', max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 129 and test 95 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-15, 'degree': 3, 'epsilon': 1.0000000000000001e-15, 'gamma': 1.0000000000000001e-15, 'kernel': 'poly'}\n",
      "SVR(C=1.0000000000000001e-15, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=1.0000000000000001e-15, gamma=1.0000000000000001e-15,\n",
      "  kernel='poly', max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-15, 'degree': 3, 'epsilon': 1.0000000000000001e-15, 'gamma': 1.0000000000000001e-15, 'kernel': 'poly'}\n",
      "SVR(C=1.0000000000000001e-15, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=1.0000000000000001e-15, gamma=1.0000000000000001e-15,\n",
      "  kernel='poly', max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "\n",
      "Dataset size read: train 127 and test 194 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 1.0000000000000001e-05, 'gamma': 316.22776601683796, 'kernel': 'sigmoid'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=1.0000000000000001e-05, gamma=316.22776601683796,\n",
      "  kernel='sigmoid', max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'sigmoid'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='sigmoid',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 194 and test 127 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'sigmoid'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='sigmoid',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 129 and test 192 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'sigmoid'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='sigmoid',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 129 and test 95 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'sigmoid'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='sigmoid',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'sigmoid'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='sigmoid',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "\n",
      "Dataset size read: train 127 and test 194 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 1.0000000000000001e-05, 'gamma': 1.0000000000000001e-05, 'kernel': 'linear'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=1.0000000000000001e-05, gamma=1.0000000000000001e-05,\n",
      "  kernel='linear', max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'linear'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='linear',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 194 and test 127 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'linear'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='linear',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 129 and test 192 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'linear'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='linear',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 129 and test 95 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'linear'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='linear',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'linear'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='linear',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "\n",
      "Dataset size read: train 127 and test 194 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 1.0000000000000001e-05, 'gamma': 1.0000000000000001e-05, 'kernel': 'rbf'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=1.0000000000000001e-05, gamma=1.0000000000000001e-05,\n",
      "  kernel='rbf', max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'rbf'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='rbf',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 194 and test 127 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'rbf'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='rbf',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 129 and test 192 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'rbf'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='rbf',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 129 and test 95 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'rbf'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='rbf',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n",
      "Dataset size read: train 192 and test 129 \n",
      "\n",
      "# Tuning hyper-parameters \n",
      "\n",
      "Starting grdsurch.fit(X_train, y_train)\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1.0000000000000001e-05, 'epsilon': 100000.0, 'gamma': 1.0000000000000001e-05, 'kernel': 'rbf'}\n",
      "SVR(C=1.0000000000000001e-05, cache_size=1024, coef0=0.0, degree=3,\n",
      "  epsilon=100000.0, gamma=1.0000000000000001e-05, kernel='rbf',\n",
      "  max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AB.pickle': {'model': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=2,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=6000, n_jobs=-1, oob_score=True, random_state=None,\n",
       "             verbose=0, warm_start=False),\n",
       "  'test_mean_y_4_comparing': 1468.9692783505157,\n",
       "  'test_rmse_4_reporting': 987.57560496918211,\n",
       "  'train_rmse_cv_4_picking': 613.22803481249457},\n",
       " 'AC.pickle': {'model': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=2,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=6000, n_jobs=-1, oob_score=True, random_state=None,\n",
       "             verbose=0, warm_start=False),\n",
       "  'test_mean_y_4_comparing': 1817.4408333333331,\n",
       "  'test_rmse_4_reporting': 1671.6004673763191,\n",
       "  'train_rmse_cv_4_picking': 139.21151562923276},\n",
       " 'AD.pickle': {'model': GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.001, loss='ls', max_depth=None,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "               n_estimators=6000, presort='auto', random_state=None,\n",
       "               subsample=1.0, verbose=0, warm_start=False),\n",
       "  'test_mean_y_4_comparing': 2371.5786315789474,\n",
       "  'test_rmse_4_reporting': 2228.1727635089037,\n",
       "  'train_rmse_cv_4_picking': 85.983265230064674},\n",
       " 'BC.pickle': {'model': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=6000, n_jobs=-1, oob_score=True, random_state=None,\n",
       "             verbose=0, warm_start=False),\n",
       "  'test_mean_y_4_comparing': 985.4341085271318,\n",
       "  'test_rmse_4_reporting': 1529.272209353755,\n",
       "  'train_rmse_cv_4_picking': 508.48719050087351},\n",
       " 'BD.pickle': {'model': GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='ls', max_depth=None,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "               n_estimators=6000, presort='auto', random_state=None,\n",
       "               subsample=1.0, verbose=0, warm_start=False),\n",
       "  'test_mean_y_4_comparing': 1277.5480620155038,\n",
       "  'test_rmse_4_reporting': 1094.3152796253225,\n",
       "  'train_rmse_cv_4_picking': 490.77658948741265},\n",
       " 'CD.pickle': {'model': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "             max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=2,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=6000, n_jobs=-1, oob_score=True, random_state=None,\n",
       "             verbose=0, warm_start=False),\n",
       "  'test_mean_y_4_comparing': 1801.356692913386,\n",
       "  'test_rmse_4_reporting': 2032.0116413680582,\n",
       "  'train_rmse_cv_4_picking': 139.11573390836983}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model_selection_4C2.pickle', 'wb') as handle:\n",
    "    pickle.dump(t, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB.pickle\n",
      "613.228034812 987.575604969 1468.96927835\n",
      "____________________________________________________________________________________________________\n",
      "BC.pickle\n",
      "508.487190501 1529.27220935 985.434108527\n",
      "____________________________________________________________________________________________________\n",
      "CD.pickle\n",
      "139.115733908 2032.01164137 1801.35669291\n",
      "____________________________________________________________________________________________________\n",
      "AC.pickle\n",
      "139.211515629 1671.60046738 1817.44083333\n",
      "____________________________________________________________________________________________________\n",
      "AD.pickle\n",
      "85.9832652301 2228.17276351 2371.57863158\n",
      "____________________________________________________________________________________________________\n",
      "BD.pickle\n",
      "490.776589487 1094.31527963 1277.54806202\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for key in t.keys():\n",
    "    print(key)\n",
    "    print(t[key]['train_rmse_cv_4_picking'],\n",
    "          t[key]['test_rmse_4_reporting'],\n",
    "          t[key]['test_mean_y_4_comparing']\n",
    "         )\n",
    "    print(100*'_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# (4C2) Response when two of four modules are chosen as training dataset\n",
    "\n",
    "'''\n",
    "AB.pickle\n",
    "613.228034812 987.575604969 1468.96927835\n",
    "____________________________________________________________________________________________________\n",
    "BC.pickle\n",
    "508.487190501 1529.27220935 985.434108527\n",
    "____________________________________________________________________________________________________\n",
    "CD.pickle\n",
    "139.115733908 2032.01164137 1801.35669291\n",
    "____________________________________________________________________________________________________\n",
    "AC.pickle\n",
    "139.211515629 1671.60046738 1817.44083333\n",
    "____________________________________________________________________________________________________\n",
    "AD.pickle\n",
    "85.9832652301 2228.17276351 2371.57863158\n",
    "____________________________________________________________________________________________________\n",
    "BD.pickle\n",
    "490.776589487 1094.31527963 1277.54806202\n",
    "____________________________________________________________________________________________________\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
