{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import all the filenames\n",
    "from allfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7  def SVRPolyCVModel(filename):\n",
    "\n",
    "8  def SVRSigmoidCVModel(filename):\n",
    "\n",
    "9  def SVRLinearCVModel(filename):\n",
    "\n",
    "10 def SVRRbfCVModel(filename):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wrapper(functionList = []):\n",
    "    if __name__ == '__main__':\n",
    "        \n",
    "        #functionList = [ SVRPolyCVModel, SVRSigmoidCVModel, SVRLinearCVModel, SVRRbfCVModel]\n",
    "\n",
    "        filenames = ['AB.pickle', 'BC.pickle', 'CD.pickle', 'AC.pickle', 'AD.pickle', 'BD.pickle' ]\n",
    "        \n",
    "        model_selection = {}\n",
    "        \n",
    "        for f in functionList:\n",
    "            print()\n",
    "            for filename in filenames:\n",
    "                out = f(filename)\n",
    "                newScore = out[filename]['train_rmse_cv_picking']\n",
    "\n",
    "                if filename in model_selection:\n",
    "                    \n",
    "                    #compare scores and select more accurate model\n",
    "                    oldScore = model_selection[filename]['train_rmse_cv_picking']\n",
    "                    if(newScore < oldScore):\n",
    "                        print(\"【【【】】】switching models for %s...\" % filename)\n",
    "                        print(\"【【【】】】newScore: %f < oldScore: %f\" % (newScore, oldScore))\n",
    "                        print(\"【【【】】】newModel: %s \\n\" % f)\n",
    "                        print(100*'_')\n",
    "                        model_selection[filename] = out[filename]\n",
    "                else:\n",
    "                    \n",
    "                    #no score to compare\n",
    "                    print(\"【【】】adding new model for %s \\n\" % filename)\n",
    "                    print(100*'_')\n",
    "                    model_selection[filename] = out[filename]\n",
    "    return model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_svr_sig = wrapper([ SVRSigmoidCVModel ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_print = t_svr_sig\n",
    "\n",
    "for key in t_print.keys():\n",
    "    print(80*'_')\n",
    "    print(key)    \n",
    "\n",
    "    print('Model: %s' % (str(t_print[key]['model'])[:200]))\n",
    "    print('Train RMSE: %f \\n' % (t_print[key]['train_rmse_cv_picking']))\n",
    "\n",
    "    #print('Test RMSE   : %f' % (t_print[key]['test_rmse_reporting']))\n",
    "    #print('Overall Mean: %f \\n' % (t_print[key]['test_mean_y_comparing']))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingA']==None):\n",
    "        print('A...TestA RMSE   : %f' % float(t_print[key]['test_rmse_reportingA'] or -1))\n",
    "        print('A...<<y_test_A Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingA'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingB']==None):\n",
    "        print('B...TestB RMSE   : %f' % float(t_print[key]['test_rmse_reportingB'] or -1))\n",
    "        print('B...<<y_test_B Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingB'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingC']==None):\n",
    "        print('C...TestC RMSE   : %f' % float(t_print[key]['test_rmse_reportingC'] or -1))\n",
    "        print('C...<<y_test_C Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingC'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingD']==None):\n",
    "        print('D...TestD RMSE   : %f' % float(t_print[key]['test_rmse_reportingD'] or -1))\n",
    "        print('D...<<y_test_D Mean>>: %f' % float(t_print[key]['test_mean_y_comparingD'] or -1))\n",
    "\n",
    "    print(80*'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the model\n",
    "import pickle\n",
    "\n",
    "#||||||||||||||||||| \n",
    "t_ = t_svr_sig\n",
    "prefix = '4C2_' + 'svr_sig'\n",
    "#||||||||||||||||||| \n",
    "\n",
    "for k in t_.keys():\n",
    "    mo   = t_[k]['model']\n",
    "    fname = prefix + '_tuned_' + str(k[:2]) + '.pickle'\n",
    "    \n",
    "    print()\n",
    "    print(k, str(mo)[:30])\n",
    "    \n",
    "    print(fname)\n",
    "    # write the model to a file\n",
    "    with open(fname, 'wb') as handle:\n",
    "        pickle.dump(mo, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_SVRLinearCVModel = wrapper([ SVRLinearCVModel ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_print = t_SVRLinearCVModel\n",
    "\n",
    "for key in t_print.keys():\n",
    "    print(80*'_')\n",
    "    print(key)    \n",
    "\n",
    "    print('Model: %s' % (str(t_print[key]['model'])[:20]))\n",
    "    print('Train RMSE: %f \\n' % (t_print[key]['train_rmse_cv_picking']))\n",
    "\n",
    "    #print('Test RMSE   : %f' % (t_print[key]['test_rmse_reporting']))\n",
    "    #print('Overall Mean: %f \\n' % (t_print[key]['test_mean_y_comparing']))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingA']==None):\n",
    "        print('A...TestA RMSE   : %f' % float(t_print[key]['test_rmse_reportingA'] or -1))\n",
    "        print('A...<<y_test_A Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingA'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingB']==None):\n",
    "        print('B...TestB RMSE   : %f' % float(t_print[key]['test_rmse_reportingB'] or -1))\n",
    "        print('B...<<y_test_B Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingB'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingC']==None):\n",
    "        print('C...TestC RMSE   : %f' % float(t_print[key]['test_rmse_reportingC'] or -1))\n",
    "        print('C...<<y_test_C Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingC'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingD']==None):\n",
    "        print('D...TestD RMSE   : %f' % float(t_print[key]['test_rmse_reportingD'] or -1))\n",
    "        print('D...<<y_test_D Mean>>: %f' % float(t_print[key]['test_mean_y_comparingD'] or -1))\n",
    "\n",
    "    print(80*'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the model\n",
    "import pickle\n",
    "\n",
    "#||||||||||||||||||| \n",
    "t_ = t_SVRLinearCVModel\n",
    "prefix = '4C2_' + 'SVRLinearCVModel'\n",
    "#||||||||||||||||||| \n",
    "\n",
    "for k in t_.keys():\n",
    "    mo   = t_[k]['model']\n",
    "    fname = prefix + '_tuned_' + str(k[:2]) + '.pickle'\n",
    "    \n",
    "    print()\n",
    "    print(k, str(mo)[:30])\n",
    "    \n",
    "    print(fname)\n",
    "    # write the model to a file\n",
    "    with open(fname, 'wb') as handle:\n",
    "        pickle.dump(mo, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_SVRPolyCVModel = wrapper([ SVRPolyCVModel ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_print = t_SVRPolyCVModel\n",
    "\n",
    "for key in t_print.keys():\n",
    "    print(80*'_')\n",
    "    print(key)    \n",
    "\n",
    "    print('Model: %s' % (str(t_print[key]['model'])[:200]))\n",
    "    print('Train RMSE: %f \\n' % (t_print[key]['train_rmse_cv_picking']))\n",
    "\n",
    "    #print('Test RMSE   : %f' % (t_print[key]['test_rmse_reporting']))\n",
    "    #print('Overall Mean: %f \\n' % (t_print[key]['test_mean_y_comparing']))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingA']==None):\n",
    "        print('A...TestA RMSE   : %f' % float(t_print[key]['test_rmse_reportingA'] or -1))\n",
    "        print('A...<<y_test_A Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingA'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingB']==None):\n",
    "        print('B...TestB RMSE   : %f' % float(t_print[key]['test_rmse_reportingB'] or -1))\n",
    "        print('B...<<y_test_B Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingB'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingC']==None):\n",
    "        print('C...TestC RMSE   : %f' % float(t_print[key]['test_rmse_reportingC'] or -1))\n",
    "        print('C...<<y_test_C Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingC'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingD']==None):\n",
    "        print('D...TestD RMSE   : %f' % float(t_print[key]['test_rmse_reportingD'] or -1))\n",
    "        print('D...<<y_test_D Mean>>: %f' % float(t_print[key]['test_mean_y_comparingD'] or -1))\n",
    "\n",
    "    print(80*'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the model\n",
    "import pickle\n",
    "\n",
    "#||||||||||||||||||| \n",
    "t_ = t_SVRPolyCVModel\n",
    "prefix = '4C2_' + 'SVRPolyCVModel'\n",
    "#||||||||||||||||||| \n",
    "\n",
    "for k in t_.keys():\n",
    "    mo   = t_[k]['model']\n",
    "    fname = prefix + '_tuned_' + str(k[:2]) + '.pickle'\n",
    "    \n",
    "    print()\n",
    "    print(k, str(mo)[:30])\n",
    "    \n",
    "    print(fname)\n",
    "    # write the model to a file\n",
    "    with open(fname, 'wb') as handle:\n",
    "        pickle.dump(mo, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rbf Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_SVRRbfCVModel = wrapper([ SVRRbfCVModel ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "BC.pickle\n",
      "Model: SVR(C=1e-10, cache_size=102400, coef0=0.0, degree=3, epsilon=10.0,\n",
      "  gamma=1e-08, kernel='rbf', max_iter=-1, shrinking=False, tol=1e-07,\n",
      "  verbose=False)\n",
      "Train RMSE: 824015.768375 \n",
      "\n",
      "A...TestA RMSE   : 1968.299191\n",
      "A...<<y_test_A Mean>>: 108.510312 \n",
      "\n",
      "D...TestD RMSE   : 1077.760867\n",
      "D...<<y_test_D Mean>>: 1274.728557\n",
      "________________________________________________________________________________\n",
      "________________________________________________________________________________\n",
      "AB.pickle\n",
      "Model: SVR(C=1e-10, cache_size=102400, coef0=0.0, degree=3, epsilon=50.0,\n",
      "  gamma=1e-08, kernel='rbf', max_iter=-1, shrinking=False, tol=1e-07,\n",
      "  verbose=False)\n",
      "Train RMSE: 1423866.435151 \n",
      "\n",
      "C...TestC RMSE   : 964.151848\n",
      "C...<<y_test_C Mean>>: 1663.210000 \n",
      "\n",
      "D...TestD RMSE   : 999.599237\n",
      "D...<<y_test_D Mean>>: 1274.728557\n",
      "________________________________________________________________________________\n",
      "________________________________________________________________________________\n",
      "BD.pickle\n",
      "Model: SVR(C=1e-10, cache_size=102400, coef0=0.0, degree=3, epsilon=50.0,\n",
      "  gamma=1e-08, kernel='rbf', max_iter=-1, shrinking=False, tol=1e-07,\n",
      "  verbose=False)\n",
      "Train RMSE: 801836.580629 \n",
      "\n",
      "A...TestA RMSE   : 1736.439018\n",
      "A...<<y_test_A Mean>>: 108.510313 \n",
      "\n",
      "C...TestC RMSE   : 932.643796\n",
      "C...<<y_test_C Mean>>: 1663.210000 \n",
      "\n",
      "________________________________________________________________________________\n",
      "________________________________________________________________________________\n",
      "CD.pickle\n",
      "Model: SVR(C=1e-10, cache_size=102400, coef0=0.0, degree=3, epsilon=50.0,\n",
      "  gamma=1e-08, kernel='rbf', max_iter=-1, shrinking=False, tol=1e-07,\n",
      "  verbose=False)\n",
      "Train RMSE: 718894.114242 \n",
      "\n",
      "A...TestA RMSE   : 1309.821639\n",
      "A...<<y_test_A Mean>>: 108.510312 \n",
      "\n",
      "B...TestB RMSE   : 1177.802817\n",
      "B...<<y_test_B Mean>>: 2371.578632 \n",
      "\n",
      "________________________________________________________________________________\n",
      "________________________________________________________________________________\n",
      "AD.pickle\n",
      "Model: SVR(C=1e-10, cache_size=102400, coef0=0.0, degree=3, epsilon=1.0, gamma=1e-08,\n",
      "  kernel='rbf', max_iter=-1, shrinking=False, tol=1e-07, verbose=False)\n",
      "Train RMSE: 685644.156511 \n",
      "\n",
      "B...TestB RMSE   : 1706.534938\n",
      "B...<<y_test_B Mean>>: 2371.578632 \n",
      "\n",
      "C...TestC RMSE   : 1250.534492\n",
      "C...<<y_test_C Mean>>: 1663.210000 \n",
      "\n",
      "________________________________________________________________________________\n",
      "________________________________________________________________________________\n",
      "AC.pickle\n",
      "Model: SVR(C=1e-10, cache_size=102400, coef0=0.0, degree=3, epsilon=20.0,\n",
      "  gamma=1e-08, kernel='rbf', max_iter=-1, shrinking=False, tol=1e-07,\n",
      "  verbose=False)\n",
      "Train RMSE: 1123701.057969 \n",
      "\n",
      "B...TestB RMSE   : 1476.967722\n",
      "B...<<y_test_B Mean>>: 2371.578632 \n",
      "\n",
      "D...TestD RMSE   : 750.541068\n",
      "D...<<y_test_D Mean>>: 1274.728557\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "t_print = t_SVRRbfCVModel\n",
    "\n",
    "for key in t_print.keys():\n",
    "    print(80*'_')\n",
    "    print(key)    \n",
    "\n",
    "    print('Model: %s' % (str(t_print[key]['model'])[:200]))\n",
    "    print('Train RMSE: %f \\n' % (t_print[key]['train_rmse_cv_picking']))\n",
    "\n",
    "    #print('Test RMSE   : %f' % (t_print[key]['test_rmse_reporting']))\n",
    "    #print('Overall Mean: %f \\n' % (t_print[key]['test_mean_y_comparing']))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingA']==None):\n",
    "        print('A...TestA RMSE   : %f' % float(t_print[key]['test_rmse_reportingA'] or -1))\n",
    "        print('A...<<y_test_A Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingA'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingB']==None):\n",
    "        print('B...TestB RMSE   : %f' % float(t_print[key]['test_rmse_reportingB'] or -1))\n",
    "        print('B...<<y_test_B Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingB'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingC']==None):\n",
    "        print('C...TestC RMSE   : %f' % float(t_print[key]['test_rmse_reportingC'] or -1))\n",
    "        print('C...<<y_test_C Mean>>: %f \\n' % float(t_print[key]['test_mean_y_comparingC'] or -1))\n",
    "\n",
    "    if(not t_print[key]['test_rmse_reportingD']==None):\n",
    "        print('D...TestD RMSE   : %f' % float(t_print[key]['test_rmse_reportingD'] or -1))\n",
    "        print('D...<<y_test_D Mean>>: %f' % float(t_print[key]['test_mean_y_comparingD'] or -1))\n",
    "\n",
    "    print(80*'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BC.pickle SVR(C=1e-10, cache_size=102400\n",
      "4C2_SVRRbfCVModel_tuned_BC.pickle\n",
      "\n",
      "AB.pickle SVR(C=1e-10, cache_size=102400\n",
      "4C2_SVRRbfCVModel_tuned_AB.pickle\n",
      "\n",
      "BD.pickle SVR(C=1e-10, cache_size=102400\n",
      "4C2_SVRRbfCVModel_tuned_BD.pickle\n",
      "\n",
      "CD.pickle SVR(C=1e-10, cache_size=102400\n",
      "4C2_SVRRbfCVModel_tuned_CD.pickle\n",
      "\n",
      "AD.pickle SVR(C=1e-10, cache_size=102400\n",
      "4C2_SVRRbfCVModel_tuned_AD.pickle\n",
      "\n",
      "AC.pickle SVR(C=1e-10, cache_size=102400\n",
      "4C2_SVRRbfCVModel_tuned_AC.pickle\n"
     ]
    }
   ],
   "source": [
    "# write the model\n",
    "import pickle\n",
    "\n",
    "#||||||||||||||||||| \n",
    "t_ = t_SVRRbfCVModel\n",
    "prefix = '4C2_' + 'SVRRbfCVModel'\n",
    "#||||||||||||||||||| \n",
    "\n",
    "for k in t_.keys():\n",
    "    mo   = t_[k]['model']\n",
    "    fname = prefix + '_tuned_' + str(k[:2]) + '.pickle'\n",
    "    \n",
    "    print()\n",
    "    print(k, str(mo)[:30])\n",
    "    \n",
    "    print(fname)\n",
    "    # write the model to a file\n",
    "    with open(fname, 'wb') as handle:\n",
    "        pickle.dump(mo, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which features were given most weights by each model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
