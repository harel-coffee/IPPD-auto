{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will create 1 dataframe from all four modules\n",
    "Shuffle and Randomly partition that one dataframe \n",
    "\n",
    "80%train + Cross validation: This data set is used to compare the performances of the prediction algorithms that were created based on the training set. We choose the algorithm that has the best performance.\n",
    "\n",
    "##############\n",
    "20%test: Once we have chosen our preferred prediction algorithm but we don't know yet how it's going to perform on \n",
    "completely new real-world data. So, we apply our chosen prediction algorithm on our test set in order to see how \n",
    "it's going to perform so we can have an idea about our algorithm's performance on new data.\n",
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateDF(featuresFile, profiledFile):\n",
    "    #reads featurefiles and projects 3 columns (ppn, sizeGB, Ytime)\n",
    "    #reads profiledFile (the table from profiling) and reads all 55 columns\n",
    "    #generates one dataframe with 58 columns and n rows (=size of profiled data from csv)\n",
    "    import pandas as pd\n",
    "    from IPython.display import display\n",
    "\n",
    "    header='ft1 ft2 ft3 ft4 ft5 ft6 ft7 ft8 ft9 ft10 ft11 ft12 ft13 ft14 ft15 ft16 ft17 \\\n",
    "    ft18 ft24 ft25 ft19 ft39 ft20 ft33 ft21 ft35 ft22 ft23 ft34 ft36 ft37 ft38 ft40 ft41 \\\n",
    "    ft42 ft43 ft44 ft45 ft46 ft48 ft47 ft49 ft51 ft50 ft52 ft53 ft54 ft55 ft26 ft27 ft28 ft29 ft30 ft31 ft32'\n",
    "    \n",
    "    def value(item):\n",
    "        return item[item.find('=')+1:]\n",
    "    \n",
    "    print(\"Reading features from %s\" % featuresFile)\n",
    "    df_features = pd.read_table(featuresFile, header=None, delimiter=',',\n",
    "                       converters={i:value for i in range(55)},\n",
    "                       names=header.split())\n",
    "    df_features = df_features.astype(float)\n",
    "    #print(df_features.head(2))\n",
    "    \n",
    "    ################################\n",
    "    #read profiledFile\n",
    "    df_profiled = pd.read_csv(profiledFile)\n",
    "    if 'Unnamed: 0' in df_profiled.columns:\n",
    "        del df_profiled['Unnamed: 0']\n",
    "    df_profiled = df_profiled.astype(float)\n",
    "    rows = df_profiled.shape[0]\n",
    "    \n",
    "    #project columns of use\n",
    "    df_profiled = df_profiled[['ppn','sizeGB','Y_time']]\n",
    "    print(\"Reading profiled file %s\\t: %s\" % (profiledFile,str(df_profiled.shape)))\n",
    "    \n",
    "    ################################\n",
    "    # create dataframe from featuresFile static program features with same #ROWs\n",
    "    frames = [df_features for i in range(rows)]\n",
    "    program_ft = pd.concat(frames)\n",
    "    program_ft.reset_index(inplace=True)\n",
    "    del program_ft['index']\n",
    "    print(\"Shape of program static features\\t\\t\\t\\t\\t: %s \" % str(program_ft.shape))\n",
    "    \n",
    "    ################################\n",
    "    # concatenate static features (55) with profiled data (3)\n",
    "    ft_plus_profiled = pd.concat([df_profiled, program_ft], axis=1, join_axes=[df_profiled.index])\n",
    "    ft_plus_profiled['y_time']=ft_plus_profiled['Y_time'] # so that y_time is last column\n",
    "    del ft_plus_profiled['Y_time']\n",
    "    print(\"Returning concatenated data frame (ft + profiled data)\\t\\t\\t: %s\" % str(ft_plus_profiled.shape))\n",
    "    #display(ft_plus_profiled.tail(5))    \n",
    "    \n",
    "    return ft_plus_profiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack two dataframes on top of each other\n",
    "def stackDFs(df1, df2):\n",
    "    import copy\n",
    "    import pandas as pd\n",
    "    \n",
    "    frames = [copy.deepcopy(df1), copy.deepcopy(df2)]\n",
    "    both = pd.concat(frames)\n",
    "    both.reset_index(inplace=True)\n",
    "    del both['index']\n",
    "    return both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "################################## cdhitdup ################################################\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading features from ./features/cdhitdup_singlecmd_features.txt\n",
      "Reading profiled file ./profiledcsvfiles/cdhitdup_ppn_sizeGB_Ytime.csv\t: (32, 3)\n",
      "Shape of program static features\t\t\t\t\t: (32, 55) \n",
      "Returning concatenated data frame (ft + profiled data)\t\t\t: (32, 58)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 58)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cdhitdup = generateDF('./features/cdhitdup_singlecmd_features.txt','./profiledcsvfiles/cdhitdup_ppn_sizeGB_Ytime.csv')\n",
    "df_cdhitdup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "##################################### frhit ################################################\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading features from ./features/frhit_singlecmd_features.txt\n",
      "Reading profiled file ./profiledcsvfiles/frhit_ppn_sizeGB_Ytime.csv\t: (96, 3)\n",
      "Shape of program static features\t\t\t\t\t: (96, 55) \n",
      "Returning concatenated data frame (ft + profiled data)\t\t\t: (96, 58)\n"
     ]
    }
   ],
   "source": [
    "df_frhit = generateDF('./features/frhit_singlecmd_features.txt', './profiledcsvfiles/frhit_ppn_sizeGB_Ytime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "##################################### velvetH ##############################################\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading features from ./features/velveth_singlecmd_features.txt\n",
      "Reading profiled file ./profiledcsvfiles/velvetH_ppn_sizeGB_Ytime.csv\t: (97, 3)\n",
      "Shape of program static features\t\t\t\t\t: (97, 55) \n",
      "Returning concatenated data frame (ft + profiled data)\t\t\t: (97, 58)\n"
     ]
    }
   ],
   "source": [
    "df_hvelvetH = generateDF('./features/velveth_singlecmd_features.txt','./profiledcsvfiles/velvetH_ppn_sizeGB_Ytime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "##################################### velvetG ##############################################\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading features from ./features/velvetg_singlecmd_features.txt\n",
      "Reading profiled file ./profiledcsvfiles/velvetG_ppn_sizeGB_Ytime.csv\t: (97, 3)\n",
      "Shape of program static features\t\t\t\t\t: (97, 55) \n",
      "Returning concatenated data frame (ft + profiled data)\t\t\t: (97, 58)\n"
     ]
    }
   ],
   "source": [
    "df_gvelvetG = generateDF('./features/velvetg_singlecmd_features.txt','./profiledcsvfiles/velvetG_ppn_sizeGB_Ytime.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack 4 dfs: df_gvelvetG, df_hvelvetH, df_cdhitdup, df_frhit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames = [df_cdhitdup, df_frhit, df_hvelvetH, df_gvelvetG]\n",
    "result = pd.concat(frames)\n",
    "result.reset_index(inplace=True)\n",
    "del result['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = result.columns[0:57]\n",
    "target = [result.columns[57]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57,\n",
       " Index(['ppn', 'sizeGB', 'ft1', 'ft2', 'ft3', 'ft4', 'ft5', 'ft6', 'ft7', 'ft8',\n",
       "        'ft9', 'ft10', 'ft11', 'ft12', 'ft13', 'ft14', 'ft15', 'ft16', 'ft17',\n",
       "        'ft18', 'ft24', 'ft25', 'ft19', 'ft39', 'ft20', 'ft33', 'ft21', 'ft35',\n",
       "        'ft22', 'ft23', 'ft34', 'ft36', 'ft37', 'ft38', 'ft40', 'ft41', 'ft42',\n",
       "        'ft43', 'ft44', 'ft45', 'ft46', 'ft48', 'ft47', 'ft49', 'ft51', 'ft50',\n",
       "        'ft52', 'ft53', 'ft54', 'ft55', 'ft26', 'ft27', 'ft28', 'ft29', 'ft30',\n",
       "        'ft31', 'ft32'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features), features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, ['y_time'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###@@@@@@@@@@@@@@@@@@@@@@@@"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#copy from concatenated dataframe\n",
    "ft0 =result.dropna().copy(deep=True)\n",
    "\n",
    "#shuffle\n",
    "####################################\n",
    "ft1  =ft0.iloc[np.random.permutation(len(ft0))]\n",
    "ft2  =ft1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 58), (161, 58), (322, 58))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Set, and |testSet|\n",
    "ft_subset, testSet = train_test_split(ft2, test_size = 0.5)\n",
    "ft = ft_subset.copy(deep=True)\n",
    "ft.shape, testSet.shape, result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = ft[features]\n",
    "y_train = ft[target].values.ravel()\n",
    "\n",
    "X_test = testSet[features]\n",
    "y_test = testSet[target].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store this partition to all modules use this\n",
    "d = { 'X_train': X_train, 'y_train': y_train, 'X_test':X_test, 'y_test': y_test }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write to file\n",
    "import pickle\n",
    "\n",
    "with open('datasetIPPD.pickle', 'wb') as handle:\n",
    "    pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read Back\n",
    "\n",
    "with open('datasetIPPD.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['X_train', 'y_train', 'X_test', 'y_test']), (160, 57))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys(), b['X_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###@@@@@@@@@@@@@@@@@@@@@@@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Partitioning Date: 2017-03-03 13:03\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"Data Partitioning Date: %s\" % datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning X_test into X_test_A, X_test_B, X_test_C, X_test_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub Partitioning Date: 2017-03-03 13:03\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"Sub Partitioning Date: %s\" % datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train', 'y_train', 'X_test', 'y_test'])\n"
     ]
    }
   ],
   "source": [
    "# Read dataset X_train, y_train etc from 'datasetIPPD.pickle'\n",
    "import pickle\n",
    "with open('datasetIPPD.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "    \n",
    "print(data.keys())\n",
    "\n",
    "#extract X_test, Y_test\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading features from ./features/cdhitdup_singlecmd_features.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft1</th>\n",
       "      <th>ft2</th>\n",
       "      <th>ft3</th>\n",
       "      <th>ft4</th>\n",
       "      <th>ft5</th>\n",
       "      <th>ft6</th>\n",
       "      <th>ft7</th>\n",
       "      <th>ft8</th>\n",
       "      <th>ft9</th>\n",
       "      <th>ft10</th>\n",
       "      <th>...</th>\n",
       "      <th>ft53</th>\n",
       "      <th>ft54</th>\n",
       "      <th>ft55</th>\n",
       "      <th>ft26</th>\n",
       "      <th>ft27</th>\n",
       "      <th>ft28</th>\n",
       "      <th>ft29</th>\n",
       "      <th>ft30</th>\n",
       "      <th>ft31</th>\n",
       "      <th>ft32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2984.0</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1794.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2087.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.41</td>\n",
       "      <td>197.65</td>\n",
       "      <td>669.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>1783.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>873.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ft1     ft2     ft3  ft4     ft5    ft6    ft7    ft8    ft9   ft10  \\\n",
       "0  2984.0  1149.0  1350.0  1.0  1794.0  748.0  140.0  865.0  833.0  244.0   \n",
       "\n",
       "   ...    ft53    ft54  ft55   ft26    ft27   ft28   ft29    ft30  ft31   ft32  \n",
       "0  ...    74.0  2087.0   3.0  83.41  197.65  669.0  230.0  1783.0  26.0  873.0  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading features from ./features/frhit_singlecmd_features.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft1</th>\n",
       "      <th>ft2</th>\n",
       "      <th>ft3</th>\n",
       "      <th>ft4</th>\n",
       "      <th>ft5</th>\n",
       "      <th>ft6</th>\n",
       "      <th>ft7</th>\n",
       "      <th>ft8</th>\n",
       "      <th>ft9</th>\n",
       "      <th>ft10</th>\n",
       "      <th>...</th>\n",
       "      <th>ft53</th>\n",
       "      <th>ft54</th>\n",
       "      <th>ft55</th>\n",
       "      <th>ft26</th>\n",
       "      <th>ft27</th>\n",
       "      <th>ft28</th>\n",
       "      <th>ft29</th>\n",
       "      <th>ft30</th>\n",
       "      <th>ft31</th>\n",
       "      <th>ft32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2286.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>126.11</td>\n",
       "      <td>152.59</td>\n",
       "      <td>223.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>681.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ft1    ft2    ft3   ft4     ft5    ft6    ft7    ft8    ft9   ft10  \\\n",
       "0  2286.0  985.0  973.0  24.0  1436.0  577.0  113.0  778.0  543.0  166.0   \n",
       "\n",
       "   ...     ft53    ft54  ft55    ft26    ft27   ft28   ft29    ft30  ft31  \\\n",
       "0  ...    104.0  2007.0   5.0  126.11  152.59  223.0  458.0  1445.0   0.0   \n",
       "\n",
       "    ft32  \n",
       "0  681.0  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading features from ./features/velvetg_singlecmd_features.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft1</th>\n",
       "      <th>ft2</th>\n",
       "      <th>ft3</th>\n",
       "      <th>ft4</th>\n",
       "      <th>ft5</th>\n",
       "      <th>ft6</th>\n",
       "      <th>ft7</th>\n",
       "      <th>ft8</th>\n",
       "      <th>ft9</th>\n",
       "      <th>ft10</th>\n",
       "      <th>...</th>\n",
       "      <th>ft53</th>\n",
       "      <th>ft54</th>\n",
       "      <th>ft55</th>\n",
       "      <th>ft26</th>\n",
       "      <th>ft27</th>\n",
       "      <th>ft28</th>\n",
       "      <th>ft29</th>\n",
       "      <th>ft30</th>\n",
       "      <th>ft31</th>\n",
       "      <th>ft32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9837.0</td>\n",
       "      <td>4069.0</td>\n",
       "      <td>3972.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6043.0</td>\n",
       "      <td>2139.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>3149.0</td>\n",
       "      <td>2417.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>...</td>\n",
       "      <td>429.0</td>\n",
       "      <td>6062.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>349.07</td>\n",
       "      <td>777.61</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>1353.0</td>\n",
       "      <td>6132.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2616.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ft1     ft2     ft3   ft4     ft5     ft6    ft7     ft8     ft9   ft10  \\\n",
       "0  9837.0  4069.0  3972.0  78.0  6043.0  2139.0  633.0  3149.0  2417.0  637.0   \n",
       "\n",
       "    ...     ft53    ft54   ft55    ft26    ft27    ft28    ft29    ft30  ft31  \\\n",
       "0   ...    429.0  6062.0  298.0  349.07  777.61  1330.0  1353.0  6132.0  67.0   \n",
       "\n",
       "     ft32  \n",
       "0  2616.0  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading features from ./features/velveth_singlecmd_features.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft1</th>\n",
       "      <th>ft2</th>\n",
       "      <th>ft3</th>\n",
       "      <th>ft4</th>\n",
       "      <th>ft5</th>\n",
       "      <th>ft6</th>\n",
       "      <th>ft7</th>\n",
       "      <th>ft8</th>\n",
       "      <th>ft9</th>\n",
       "      <th>ft10</th>\n",
       "      <th>...</th>\n",
       "      <th>ft53</th>\n",
       "      <th>ft54</th>\n",
       "      <th>ft55</th>\n",
       "      <th>ft26</th>\n",
       "      <th>ft27</th>\n",
       "      <th>ft28</th>\n",
       "      <th>ft29</th>\n",
       "      <th>ft30</th>\n",
       "      <th>ft31</th>\n",
       "      <th>ft32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2301.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>979.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>88.28</td>\n",
       "      <td>195.57</td>\n",
       "      <td>224.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>558.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ft1    ft2    ft3   ft4     ft5    ft6    ft7    ft8    ft9   ft10  \\\n",
       "0  2301.0  833.0  979.0  14.0  1428.0  503.0  132.0  631.0  628.0  160.0   \n",
       "\n",
       "   ...    ft53    ft54  ft55   ft26    ft27   ft28   ft29    ft30  ft31   ft32  \n",
       "0  ...    89.0  1295.0  22.0  88.28  195.57  224.0  347.0  1492.0  13.0  558.0  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For A, Total matches found : 17 \n",
      "For B, Total matches found : 48 \n",
      "For C, Total matches found : 47 \n",
      "For D, Total matches found : 49 \n",
      "161\n"
     ]
    }
   ],
   "source": [
    "# Separate X_A, y_A, X_B, y_B ... from X_test and y_test\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "def featureReader(featuresFile):\n",
    "    #reads featurefiles and projects 3 columns (ppn, sizeGB, Ytime)\n",
    "    #reads profiledFile (the table from profiling) and reads all 55 columns\n",
    "    #generates one dataframe with 58 columns and n rows (=size of profiled data from csv)\n",
    "    import pandas as pd\n",
    "    from IPython.display import display\n",
    "\n",
    "    header='ft1 ft2 ft3 ft4 ft5 ft6 ft7 ft8 ft9 ft10 ft11 ft12 ft13 ft14 ft15 ft16 ft17 ft18 ft24 ft25 ft19 ft39 ft20 ft33 ft21 ft35 ft22 ft23 ft34 ft36 ft37 ft38 ft40 ft41     ft42 ft43 ft44 ft45 ft46 ft48 ft47 ft49 ft51 ft50 ft52 ft53 ft54 ft55 ft26 ft27 ft28 ft29 ft30 ft31 ft32'\n",
    "    \n",
    "    def value(item):\n",
    "        return item[item.find('=')+1:]\n",
    "    \n",
    "    print(\"Reading features from %s\" % featuresFile)\n",
    "    df_features = pd.read_table(featuresFile, header=None, delimiter=',',\n",
    "                       converters={i:value for i in range(55)},\n",
    "                       names=header.split())\n",
    "    df_features = df_features.astype(float)\n",
    "    return df_features\n",
    "\n",
    "# In[104]:\n",
    "\n",
    "# Signature for A\n",
    "from IPython.display import display\n",
    "signatureA = featureReader('./features/cdhitdup_singlecmd_features.txt')\n",
    "display(signatureA)\n",
    "\n",
    "# In[105]:\n",
    "\n",
    "# Signature for B\n",
    "signatureB = featureReader('./features/frhit_singlecmd_features.txt')\n",
    "display(signatureB)\n",
    "\n",
    "# ## A=cdhitdup, B=frhit, C=velvetG, D=velvetH\n",
    "\n",
    "# In[106]:\n",
    "\n",
    "# Signature for C\n",
    "signatureC = featureReader('./features/velvetg_singlecmd_features.txt')\n",
    "display(signatureC)\n",
    "\n",
    "# In[107]:\n",
    "\n",
    "# Signature for D\n",
    "signatureD = featureReader('./features/velveth_singlecmd_features.txt')\n",
    "display(signatureD)\n",
    "\n",
    "# ## Extractor for extracting features\n",
    "\n",
    "# In[145]:\n",
    "\n",
    "cols = ['ft1', 'ft2', 'ft3', 'ft4', 'ft5', 'ft6', 'ft7', 'ft8', 'ft9', 'ft10',\n",
    "       'ft11', 'ft12', 'ft13', 'ft14', 'ft15', 'ft16', 'ft17', 'ft18', 'ft24',\n",
    "       'ft25', 'ft19', 'ft39', 'ft20', 'ft33', 'ft21', 'ft35', 'ft22', 'ft23',\n",
    "       'ft34', 'ft36', 'ft37', 'ft38', 'ft40', 'ft41', 'ft42', 'ft43', 'ft44',\n",
    "       'ft45', 'ft46', 'ft48', 'ft47', 'ft49', 'ft51', 'ft50', 'ft52', 'ft53',\n",
    "       'ft54', 'ft55', 'ft26', 'ft27', 'ft28', 'ft29', 'ft30', 'ft31', 'ft32']\n",
    " \n",
    "\n",
    "# In[273]:\n",
    "\n",
    "def extractor(name, signature, X_test, y_test):\n",
    "    import pandas as pd\n",
    "    import numpy  as np\n",
    "    import copy\n",
    "    \n",
    "    count = 0\n",
    "    xt = pd.DataFrame(columns = X_test.columns)\n",
    "    yt = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        if(all(X_test[cols].iloc[[i]].values[0] == signature.iloc[[0]].values[0])):\n",
    "            #print(X_test[cols].iloc[[i]].values[0])\n",
    "            #print(signature.iloc[[0]].values[0])\n",
    "            count = count + 1\n",
    "            # make deep copies\n",
    "            xt = xt.append(copy.deepcopy(X_test.iloc[[i]]), ignore_index=True)\n",
    "            yt.append(copy.deepcopy(y_test[i]))\n",
    "            \n",
    "    print(\"For %s, Total matches found : %d \" % (name,count))\n",
    "    \n",
    "    return xt,np.asarray(yt)\n",
    "\n",
    "\n",
    "# In[274]:\n",
    "X_A, y_A = extractor('A',signatureA, X_test, y_test)\n",
    "X_A.shape, len(y_A)\n",
    "\n",
    "# In[275]:\n",
    "X_B, y_B = extractor('B',signatureB, X_test, y_test)\n",
    "X_B.shape, len(y_B)\n",
    "\n",
    "# In[276]:\n",
    "X_C, y_C = extractor('C',signatureC, X_test, y_test)\n",
    "X_C.shape, len(y_C)\n",
    "\n",
    "# In[277]:\n",
    "X_D, y_D = extractor('D',signatureD, X_test, y_test)\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add to dictionary: { X_test_A, y_test_A }\n",
    "data['X_test_A']=X_A\n",
    "data['y_test_A']=y_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add to dictionary: { X_test_B, y_test_B }\n",
    "data['X_test_B']=X_B\n",
    "data['y_test_B']=y_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add to dictionary: { X_test_C, y_test_C }\n",
    "data['X_test_C']=X_C\n",
    "data['y_test_C']=y_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_train', 'y_train', 'X_test', 'y_test', 'X_test_A', 'y_test_A', 'X_test_B', 'y_test_B', 'X_test_C', 'y_test_C', 'X_test_D', 'y_test_D'])\n"
     ]
    }
   ],
   "source": [
    "# Add to dictionary: { X_test_D, y_test_D }\n",
    "data['X_test_D']=X_D\n",
    "data['y_test_D']=y_D\n",
    "\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WRITE the dictionary 'd' back to file 'datasetIPPD.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write to file\n",
    "import pickle\n",
    "\n",
    "with open('datasetIPPD.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Partitioning Date: 2017-03-03 13:04\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"Data Partitioning Date: %s\" % datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
