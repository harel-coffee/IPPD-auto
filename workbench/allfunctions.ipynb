{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "import numpy as np\n",
    "\n",
    "def rmse_scorer(model, X, y): \n",
    "    y_predict = model.predict(X)\n",
    "    k = np.sqrt(mean_squared_error(y, y_predict))\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "1  def LassoCVModel(filename)\n",
    "\n",
    "2  def OMPCVModel(filename)\n",
    "\n",
    "3  def GradientBoostingCVModel(filename)\n",
    "\n",
    "4  def RandomForestCVModel(filename)\n",
    "\n",
    "5  def RidgeCVModel(filename)\n",
    "\n",
    "6  def ElasticNetCVModel(filename)\n",
    "\n",
    "7  def SVRPolyCVModel(filename)\n",
    "\n",
    "8  def SVRSigmoidCVModel(filename)\n",
    "\n",
    "9  def SVRLinearCVModel(filename)\n",
    "\n",
    "10 def SVRRbfCVModel(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>>\n",
    "<<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>>\n",
    "<<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>><<>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4\n",
    "def RandomForestCVModel(filename):\n",
    "    #open file and get the dictionary\n",
    "    import pickle\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.ensemble.forest import RandomForestRegressor\n",
    "    from numpy.random import RandomState\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    #extract X_train, y_train, X_test, t_test\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    print(\"Dataset size read: train %d and test %d \\n\" %(len(y_train), len(y_test)))\n",
    "    \n",
    "    #Normalize\n",
    "    X_train = preprocessing.normalize(X_train, norm='l1')\n",
    "    X_test  = preprocessing.normalize(X_test,  norm='l1')\n",
    "    \n",
    "    ##############################################################\n",
    "    tuned_parameters = []\n",
    "    tuned_parameters.append( { \n",
    "                              \"n_estimators\" :[2000, 4000, 6000]\n",
    "                            })\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters \")\n",
    "    print()\n",
    "\n",
    "    grdsurch = GridSearchCV(RandomForestRegressor(n_estimators=6000, criterion='mse', max_depth=None, \n",
    "                                                  min_samples_split=2, \n",
    "                                                  min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                                                  max_leaf_nodes=None, min_impurity_split=1e-07, \n",
    "                                                  bootstrap=True, oob_score=True, \n",
    "                                                  n_jobs=-1, random_state=None, verbose=0, warm_start=False), \n",
    "                       tuned_parameters, \n",
    "                       cv=3, \n",
    "                       n_jobs=-1, \n",
    "                       scoring=rmse_scorer)\n",
    "    print('Starting grdsurch.fit(X_train, y_train)')\n",
    "    \n",
    "    grdsurch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grdsurch.best_params_)\n",
    "    \n",
    "    print(grdsurch.best_estimator_)\n",
    "    print()\n",
    "    rmse_cv = grdsurch.best_score_\n",
    "\n",
    "    #Reporting Score on Test Set\n",
    "    model               = grdsurch.best_estimator_\n",
    "    reporting_testscore = rmse_scorer(model, X_test, y_test)\n",
    "    \n",
    "    return {filename: {'train_rmse_cv_4_picking': rmse_cv, \n",
    "                       'test_rmse_4_reporting': reporting_testscore, \n",
    "                       'test_mean_y_4_comparing': y_test.mean(),\n",
    "                       'model': model\n",
    "                      }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5\n",
    "def RidgeCVModel(filename):\n",
    "    #open file and get the dictionary\n",
    "    import pickle\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    #extract X_train, y_train, X_test, t_test\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    print(\"Dataset size read: train %d and test %d \\n\" %(len(y_train), len(y_test)))\n",
    "    \n",
    "    #Normalize\n",
    "    #X_train = preprocessing.normalize(X_train, norm='l1')\n",
    "    #X_test  = preprocessing.normalize(X_test,  norm='l1')\n",
    "    \n",
    "    # Scale data\n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    X_train = standard_scaler.fit_transform(X_train)\n",
    "    X_test  = standard_scaler.transform(X_test)\n",
    "    \n",
    "    ##############################################################\n",
    "    tuned_parameters = []\n",
    "    tuned_parameters.append( {'alpha' : np.logspace(-15, -10, 100) })\n",
    "    ##############################################################\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters \")\n",
    "    print()\n",
    "\n",
    "    # Ridge Regression (L2)\n",
    "    grdsurch = GridSearchCV(Ridge(alpha=1.0, fit_intercept=True, \n",
    "                             normalize=False, copy_X=True, max_iter=None, tol=1e-20, \n",
    "                             solver='auto', random_state=None), \n",
    "                       tuned_parameters, \n",
    "                       cv=3, \n",
    "                       n_jobs=-1, \n",
    "                       scoring=rmse_scorer)\n",
    "    print('Starting grdsurch.fit(X_train, y_train)')\n",
    "    \n",
    "    grdsurch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grdsurch.best_params_)\n",
    "    \n",
    "    print(grdsurch.best_estimator_)\n",
    "    print()\n",
    "    rmse_cv = grdsurch.best_score_\n",
    "\n",
    "    #Reporting Score on Test Set\n",
    "    model               = grdsurch.best_estimator_\n",
    "    reporting_testscore = rmse_scorer(model, X_test, y_test)\n",
    "    \n",
    "    return {filename: {'train_rmse_cv_4_picking': rmse_cv, \n",
    "                       'test_rmse_4_reporting': reporting_testscore, \n",
    "                       'test_mean_y_4_comparing': y_test.mean(),\n",
    "                       'model': model\n",
    "                      }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6\n",
    "def ElasticNetCVModel(filename):\n",
    "    #open file and get the dictionary\n",
    "    import pickle\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    #extract X_train, y_train, X_test, t_test\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    print(\"Dataset size read: train %d and test %d \\n\" %(len(y_train), len(y_test)))\n",
    "    \n",
    "    #Normalize\n",
    "    #X_train = preprocessing.normalize(X_train, norm='l1')\n",
    "    #X_test  = preprocessing.normalize(X_test,  norm='l1')\n",
    "    \n",
    "    #Scale\n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    X_train = standard_scaler.fit_transform(X_train)\n",
    "    X_test  = standard_scaler.transform(X_test)\n",
    "    \n",
    "    ##############################################################\n",
    "    tuned_parameters = []\n",
    "    tuned_parameters.append( { 'alpha'   : np.logspace(-15, -10, 20), \n",
    "                               'l1_ratio': [.01]  \n",
    "                             }\n",
    "                           ) \n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters \")\n",
    "    print()\n",
    "\n",
    "    # Elastic Net (L1 + L2)\n",
    "    # Linear regression with combined L1 and L2 priors as regularizer\n",
    "    grdsurch = GridSearchCV(ElasticNet(alpha=1.0, l1_ratio=0.5, fit_intercept=True, normalize=False, \n",
    "                                       precompute=False, max_iter=1e7, copy_X=True, tol=1e-20, \n",
    "                                       warm_start=False, positive=False, \n",
    "                                       random_state=None, selection='cyclic'), \n",
    "                       tuned_parameters, \n",
    "                       cv=3, \n",
    "                       n_jobs=-1, \n",
    "                       scoring=rmse_scorer)\n",
    "    ''' \n",
    "    \n",
    "    grdsurch = RandomizedSearchCV(estimator=ElasticNet(alpha=1.0, l1_ratio=0.5, fit_intercept=True, normalize=False, \n",
    "                                       precompute=False, max_iter=1e9, copy_X=True, tol=1e-20, \n",
    "                                       warm_start=False, positive=False, \n",
    "                                       random_state=None, selection='cyclic'), \n",
    "                                  param_distributions=tuned_parameters[0], \n",
    "                                  n_iter=10, scoring=rmse_scorer, \n",
    "                                  fit_params=None, n_jobs=-1, \n",
    "                                  iid=True, refit=True, cv=3, \n",
    "                                  verbose=0, pre_dispatch='2*n_jobs', \n",
    "                                  random_state=None, \n",
    "                                  error_score='raise', \n",
    "                                  return_train_score=True)\n",
    "    ''' \n",
    "    \n",
    "    print('Starting grdsurch.fit(X_train, y_train)')\n",
    "    \n",
    "    grdsurch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grdsurch.best_params_)\n",
    "    \n",
    "    print(grdsurch.best_estimator_)\n",
    "    print()\n",
    "    rmse_cv = grdsurch.best_score_\n",
    "\n",
    "    #Reporting Score on Test Set\n",
    "    model               = grdsurch.best_estimator_\n",
    "    reporting_testscore = rmse_scorer(model, X_test, y_test)\n",
    "    \n",
    "    return {filename: {'train_rmse_cv_4_picking': rmse_cv, \n",
    "                       'test_rmse_4_reporting': reporting_testscore, \n",
    "                       'test_mean_y_4_comparing': y_test.mean(),\n",
    "                       'model': model\n",
    "                      }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#7\n",
    "def SVRPolyCVModel(filename):\n",
    "    #open file and get the dictionary\n",
    "    import pickle\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    #extract X_train, y_train, X_test, t_test\n",
    "    X_trai  = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_tes   = data['X_test']\n",
    "    y_test  = data['y_test']\n",
    "    print(\"Dataset size read: train %d and test %d \\n\" %(len(y_train), len(y_test)))\n",
    "    \n",
    "    #Normalize\n",
    "    #X_train = preprocessing.normalize(X_train, norm='l1')\n",
    "    #X_test  = preprocessing.normalize(X_test,  norm='l1')\n",
    "    \n",
    "    #Standard Scaling for SVR\n",
    "    # Scale data\n",
    "    standard_scaler = preprocessing.StandardScaler()\n",
    "    X_train = standard_scaler.fit_transform(X_trai)\n",
    "    X_test  = standard_scaler.transform(X_tes)\n",
    "    \n",
    "    # -- a -- ‘poly’ \n",
    "    ##############################################################\n",
    "    tuned_parameters = []\n",
    "    \n",
    "    tuned_parameters.append({\n",
    "                             'gamma'  : np.logspace(-15, 3, 2),\n",
    "                             'C'      : np.logspace(-5, 15, 2),\n",
    "                             'degree' : [6]\n",
    "                            })\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters... \")\n",
    "    print()\n",
    "\n",
    "    grdsurch = GridSearchCV(SVR(kernel='poly', degree=3, \n",
    "                                gamma='auto', coef0=0.0, tol=1e-2, C=1.0, \n",
    "                                epsilon=0.1, shrinking=False, cache_size=20*1024, \n",
    "                                verbose=False, max_iter=1e9), \n",
    "                       tuned_parameters, \n",
    "                       cv=3, \n",
    "                       n_jobs=-1, \n",
    "                       scoring=rmse_scorer)\n",
    "    print('Starting grdsurch.fit(X_train, y_train)')\n",
    "    \n",
    "    grdsurch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grdsurch.best_params_)\n",
    "    \n",
    "    print(grdsurch.best_estimator_)\n",
    "    print()\n",
    "    rmse_cv = grdsurch.best_score_\n",
    "\n",
    "    #Reporting Score on Test Set\n",
    "    model               = grdsurch.best_estimator_\n",
    "    reporting_testscore = rmse_scorer(model, X_test, y_test)\n",
    "    \n",
    "    return {filename: {'train_rmse_cv_4_picking': rmse_cv, \n",
    "                       'test_rmse_4_reporting': reporting_testscore, \n",
    "                       'test_mean_y_4_comparing': y_test.mean(),\n",
    "                       'model': model\n",
    "                      }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#8\n",
    "def SVRSigmoidCVModel(filename):\n",
    "    #open file and get the dictionary\n",
    "    import pickle\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    import numpy as np\n",
    "\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    #extract X_train, y_train, X_test, t_test\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    print(\"Dataset size read: train %d and test %d \\n\" %(len(y_train), len(y_test)))\n",
    "    \n",
    "    #Normalize\n",
    "    X_train = preprocessing.normalize(X_train, norm='l1')\n",
    "    X_test  = preprocessing.normalize(X_test,  norm='l1')\n",
    "    \n",
    "    # -- b -- ‘sigmoid’\n",
    "    ##############################################################\n",
    "    tuned_parameters = []\n",
    "    \n",
    "    tuned_parameters.append({\n",
    "                             'gamma'  : np.logspace(-15, 3, 1),\n",
    "                             'C'      : np.logspace(-5, 15, 1)\n",
    "                            }\n",
    "                            )    \n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters \")\n",
    "    print()\n",
    "\n",
    "    grdsurch = GridSearchCV(SVR(kernel='sigmoid', degree=3, \n",
    "                                gamma='auto', coef0=0.0, tol=1e-7, C=1.0, \n",
    "                                epsilon=0.1, shrinking=False, cache_size=20*1024, \n",
    "                                verbose=False, max_iter=-1), \n",
    "                       tuned_parameters, \n",
    "                       cv=3, \n",
    "                       n_jobs=-1, \n",
    "                       scoring=rmse_scorer)\n",
    "    print('Starting grdsurch.fit(X_train, y_train)')\n",
    "    \n",
    "    grdsurch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grdsurch.best_params_)\n",
    "    \n",
    "    print(grdsurch.best_estimator_)\n",
    "    print()\n",
    "    rmse_cv = grdsurch.best_score_\n",
    "\n",
    "    #Reporting Score on Test Set\n",
    "    model               = grdsurch.best_estimator_\n",
    "    reporting_testscore = rmse_scorer(model, X_test, y_test)\n",
    "    \n",
    "    return {filename: {'train_rmse_cv_4_picking': rmse_cv, \n",
    "                       'test_rmse_4_reporting': reporting_testscore, \n",
    "                       'test_mean_y_4_comparing': y_test.mean(),\n",
    "                       'model': model\n",
    "                      }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9\n",
    "\n",
    "def SVRLinearCVModel(filename):\n",
    "    #open file and get the dictionary\n",
    "    import pickle\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    #extract X_train, y_train, X_test, t_test\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    print(\"Dataset size read: train %d and test %d \\n\" %(len(y_train), len(y_test)))\n",
    "    \n",
    "    #Normalize\n",
    "    X_train = preprocessing.normalize(X_train, norm='l1')\n",
    "    X_test  = preprocessing.normalize(X_test,  norm='l1')\n",
    "    \n",
    "    # -- c -- ‘linear’ \n",
    "    ##############################################################\n",
    "    tuned_parameters = []\n",
    "    \n",
    "    \n",
    "    tuned_parameters.append({\n",
    "                             # 'gamma'  : np.logspace(-15, 3, 5),\n",
    "                             'C'      : np.logspace(-5, 15, 5)\n",
    "                            })\n",
    "\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters \")\n",
    "    print()\n",
    "\n",
    "    grdsurch = GridSearchCV(SVR(kernel='linear', degree=3, \n",
    "                                gamma='auto', coef0=0.0, tol=1e-7, C=1.0, \n",
    "                                epsilon=0.1, shrinking=False, cache_size=20*1024, \n",
    "                                verbose=False, max_iter=-1), \n",
    "                       tuned_parameters, \n",
    "                       cv=3, \n",
    "                       n_jobs=-1, \n",
    "                       scoring=rmse_scorer)\n",
    "    print('Starting grdsurch.fit(X_train, y_train)')\n",
    "    \n",
    "    grdsurch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grdsurch.best_params_)\n",
    "    \n",
    "    print(grdsurch.best_estimator_)\n",
    "    print()\n",
    "    rmse_cv = grdsurch.best_score_\n",
    "\n",
    "    #Reporting Score on Test Set\n",
    "    model               = grdsurch.best_estimator_\n",
    "    reporting_testscore = rmse_scorer(model, X_test, y_test)\n",
    "    \n",
    "    return {filename: {'train_rmse_cv_4_picking': rmse_cv, \n",
    "                       'test_rmse_4_reporting': reporting_testscore, \n",
    "                       'test_mean_y_4_comparing': y_test.mean(),\n",
    "                       'model': model\n",
    "                      }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#10\n",
    "\n",
    "def SVRRbfCVModel(filename):\n",
    "    #open file and get the dictionary\n",
    "    import pickle\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    #extract X_train, y_train, X_test, t_test\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    print(\"Dataset size read: train %d and test %d \\n\" %(len(y_train), len(y_test)))\n",
    "    \n",
    "    #Normalize\n",
    "    X_train = preprocessing.normalize(X_train, norm='l1')\n",
    "    X_test  = preprocessing.normalize(X_test,  norm='l1')\n",
    "    \n",
    "    # -- d -- ‘rbf’\n",
    "    ##############################################################\n",
    "    tuned_parameters = []\n",
    "\n",
    "    tuned_parameters.append({ \n",
    "                             'gamma'  : np.logspace(-15, 3, 5),\n",
    "                             'C'      : np.logspace(-5, 15, 5)\n",
    "                             })\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters \")\n",
    "    print()\n",
    "\n",
    "    grdsurch = GridSearchCV(SVR(kernel='rbf', degree=3, \n",
    "                                gamma='auto', coef0=0.0, tol=1e-7, C=1.0, \n",
    "                                epsilon=0.1, shrinking=False, cache_size=20*1024, \n",
    "                                verbose=False, max_iter=-1), \n",
    "                       tuned_parameters, \n",
    "                       cv=3, \n",
    "                       n_jobs=-1, \n",
    "                       scoring=rmse_scorer)\n",
    "    print('Starting grdsurch.fit(X_train, y_train)')\n",
    "    \n",
    "    grdsurch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grdsurch.best_params_)\n",
    "    \n",
    "    print(grdsurch.best_estimator_)\n",
    "    print()\n",
    "    rmse_cv = grdsurch.best_score_\n",
    "\n",
    "    #Reporting Score on Test Set\n",
    "    model               = grdsurch.best_estimator_\n",
    "    reporting_testscore = rmse_scorer(model, X_test, y_test)\n",
    "    \n",
    "    return {filename: {'train_rmse_cv_4_picking': rmse_cv, \n",
    "                       'test_rmse_4_reporting': reporting_testscore, \n",
    "                       'test_mean_y_4_comparing': y_test.mean(),\n",
    "                       'model': model\n",
    "                      }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OK below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 OK\n",
    "def LassoCVModel(filename):\n",
    "    #open file and get the dictionary\n",
    "    import pickle\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    #extract X_train, y_train, X_test, t_test\n",
    "    X_train  = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_test   = data['X_test']\n",
    "    y_test  = data['y_test']\n",
    "    print(\"Dataset size read: train %d and test %d \\n\" %(len(y_train), len(y_test)))\n",
    "    \n",
    "    #Normalize\n",
    "    X_train = preprocessing.normalize(X_train, norm='l1')\n",
    "    X_test  = preprocessing.normalize(X_test,  norm='l1')\n",
    "    \n",
    "    # Scale data\n",
    "    #standard_scaler = preprocessing.StandardScaler()\n",
    "    #X_train = standard_scaler.fit_transform(X_train)\n",
    "    #X_test  = standard_scaler.transform(X_test)\n",
    "    \n",
    "    ##############################################################\n",
    "    tuned_parameters = []\n",
    "    tuned_parameters.append( {'alpha' : np.logspace(-4, 10, 30),\n",
    "                              'precompute' : [True, False]\n",
    "                             } )\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters \")\n",
    "    print()\n",
    "\n",
    "    # Lasso (L1)\n",
    "    grdsurch = GridSearchCV(Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, \n",
    "                                  copy_X=True, max_iter=1e7, tol=1e-6, warm_start=False, \n",
    "                                  positive=False, random_state=None, selection='random'), \n",
    "                       tuned_parameters, \n",
    "                       cv=3, \n",
    "                       n_jobs=-1, \n",
    "                       scoring=rmse_scorer)\n",
    "    print('Starting grdsurch.fit(X_train, y_train)')\n",
    "    \n",
    "    grdsurch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grdsurch.best_params_)\n",
    "    \n",
    "    print(grdsurch.best_estimator_)\n",
    "    print()\n",
    "    rmse_cv = grdsurch.best_score_\n",
    "\n",
    "    #Reporting Score on Test Set\n",
    "    model               = grdsurch.best_estimator_\n",
    "    reporting_testscore = rmse_scorer(model, X_test, y_test)\n",
    "    \n",
    "    return {filename: {'train_rmse_cv_4_picking': rmse_cv, \n",
    "                       'test_rmse_4_reporting': reporting_testscore, \n",
    "                       'test_mean_y_4_comparing': y_test.mean(),\n",
    "                       'model': model\n",
    "                      }\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2 OK\n",
    "def OMPCVModel(filename):\n",
    "    #open file and get the dictionary\n",
    "    import pickle\n",
    "    from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    #extract X_train, y_train, X_test, t_test\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    print(\"Dataset size read: train %d and test %d \\n\" %(len(y_train), len(y_test)))\n",
    "    \n",
    "    #Normalize\n",
    "    #X_train = preprocessing.normalize(X_train, norm='l1')\n",
    "    #X_test  = preprocessing.normalize(X_test,  norm='l1')\n",
    "    \n",
    "    #‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ \n",
    "    ##############################################################\n",
    "    tuned_parameters = []\n",
    "    tuned_parameters.append({'tol' : [1e-20, 1e-15, 1e-11],\n",
    "                             'n_nonzero_coefs' : [3, 7, 14, 28]\n",
    "                            \n",
    "                            })\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters \")\n",
    "    print()\n",
    "    \n",
    "    # OMP\n",
    "    grdsurch = GridSearchCV(OrthogonalMatchingPursuit(n_nonzero_coefs=None, \n",
    "                                                      tol=None, fit_intercept=True, \n",
    "                                                      normalize=True, precompute='auto'), \n",
    "                       tuned_parameters, \n",
    "                       cv=3, \n",
    "                       n_jobs=-1, \n",
    "                       scoring=rmse_scorer)\n",
    "    \n",
    "    print('Starting grdsurch.fit(X_train, y_train)')\n",
    "    \n",
    "    grdsurch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grdsurch.best_params_)\n",
    "    \n",
    "    print(grdsurch.best_estimator_)\n",
    "    print()\n",
    "    rmse_cv = grdsurch.best_score_\n",
    "\n",
    "    #Reporting Score on Test Set\n",
    "    model               = grdsurch.best_estimator_\n",
    "    reporting_testscore = rmse_scorer(model, X_test, y_test)\n",
    "    \n",
    "    \n",
    "    return {filename: {'train_rmse_cv_4_picking': rmse_cv, \n",
    "                       'test_rmse_4_reporting': reporting_testscore, \n",
    "                       'test_mean_y_4_comparing': y_test.mean(),\n",
    "                       'model': model\n",
    "                      }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 OK\n",
    "def GradientBoostingCVModel(filename):\n",
    "    #open file and get the dictionary\n",
    "    import pickle\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from numpy.random import RandomState\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    with open(filename, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "    #extract X_train, y_train, X_test, t_test\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    print(\"Dataset size read: train %d and test %d \\n\" %(len(y_train), len(y_test)))\n",
    "    \n",
    "    #Normalize\n",
    "    X_train = preprocessing.normalize(X_train, norm='l1')\n",
    "    X_test  = preprocessing.normalize(X_test,  norm='l1')\n",
    "    \n",
    "    ##############################################################\n",
    "    tuned_parameters = [     {  \"n_estimators\" :[6000],\n",
    "                               \"loss\" : ['ls'],\n",
    "                                \"learning_rate\": [0.005, 0.01, 0.001]\n",
    "                             }\n",
    "                       ]\n",
    "\n",
    "    \n",
    "    ##############################################################\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters \")\n",
    "    print()\n",
    "\n",
    "    #Boosting\n",
    "    grdsurch = GridSearchCV(GradientBoostingRegressor(loss='ls', learning_rate=0.1, n_estimators=6000, subsample=1.0, \n",
    "                                                      criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, \n",
    "                                                      min_weight_fraction_leaf=0.0, max_depth=None, \n",
    "                                                      min_impurity_split=1e-07, \n",
    "                                                      init=None, random_state=None, max_features=None, alpha=0.9, \n",
    "                                                      verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto'), \n",
    "                       tuned_parameters, \n",
    "                       cv=3, \n",
    "                       n_jobs=-1, \n",
    "                       scoring=rmse_scorer)\n",
    "    print('Starting grdsurch.fit(X_train, y_train)')\n",
    "    \n",
    "    grdsurch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grdsurch.best_params_)\n",
    "    \n",
    "    print(grdsurch.best_estimator_)\n",
    "    print()\n",
    "    rmse_cv = grdsurch.best_score_\n",
    "\n",
    "    #Reporting Score on Test Set\n",
    "    model               = grdsurch.best_estimator_\n",
    "    reporting_testscore = rmse_scorer(model, X_test, y_test)\n",
    "    \n",
    "    return {filename: {'train_rmse_cv_4_picking': rmse_cv, \n",
    "                       'test_rmse_4_reporting': reporting_testscore, \n",
    "                       'test_mean_y_4_comparing': y_test.mean(),\n",
    "                       'model': model\n",
    "                      }}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
